{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle_TPS_2021_10_Data_Prep.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF5KXSA0t0s0"
      },
      "source": [
        "# Kaggle TPS 2021 10 Data Prep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f56SbQayHCy"
      },
      "source": [
        "The October dataset is particularly large so if you run this in colab, you'll need High RAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra4nAGk0uNGD"
      },
      "source": [
        "## PIP Installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_o5xDYgtlFA"
      },
      "source": [
        "import os\n",
        "from google.colab import output\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW8Yk2sMw3XO",
        "outputId": "b2588407-3275-4ea6-b615-6fc2cbeda375"
      },
      "source": [
        "working_dir = 'MyDrive/kaggle/202110'\n",
        "drive_dir = '/content/drive/'\n",
        "model_dir = 'models'\n",
        "output_dir = 'output'\n",
        "data_dir = 'data'\n",
        "from google.colab import drive\n",
        "drive.mount(drive_dir, force_remount=True)  # Do this once only\n",
        "\n",
        "mounted_drive = f'{drive_dir}/{working_dir}' #''\n",
        "os.chdir(mounted_drive)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9Aax79Eza-B"
      },
      "source": [
        "If you want to directly download the kaggle files to your Google Colab environment\n",
        "\n",
        "From https://www.analyticsvidhya.com/blog/2021/05/10-colab-tips-and-hacks-for-efficient-use-of-it/\n",
        "\n",
        "https://github.com/Kaggle/kaggle-api\n",
        "\n",
        "You can pull the datasets directly from Kaggle\n",
        "1.  Go to your account page on kaggle.com and scroll to API to get your token\n",
        "2.  Download the token \n",
        "3.  Copy it to Google Drive - most people put it in the .kaggle directory\n",
        "4.  Set enviornment variable KAGGLE_CONFIG_DIR\n",
        "5.  ```\n",
        "! pip install kaggle\n",
        "kaggle competitions download -c tabular-playground-series-oct-2021```\n",
        "6.  You may need to add logic to move the files where you want them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0iyzd7Nxe7D"
      },
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/MyDrive/.kaggle\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy9Fv22huNgD",
        "outputId": "4150bf21-77ac-45e2-affd-8312be522709"
      },
      "source": [
        "!pip install kaggle\n",
        "!kaggle competitions download -c tabular-playground-series-oct-2021"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading test.csv.zip to /content/drive/My Drive/kaggle/202110\n",
            " 98% 431M/438M [00:07<00:00, 52.4MB/s]\n",
            "100% 438M/438M [00:08<00:00, 57.3MB/s]\n",
            "Downloading sample_submission.csv.zip to /content/drive/My Drive/kaggle/202110\n",
            " 89% 1.00M/1.12M [00:00<00:00, 2.96MB/s]\n",
            "100% 1.12M/1.12M [00:00<00:00, 2.84MB/s]\n",
            "Downloading train.csv.zip to /content/drive/My Drive/kaggle/202110\n",
            "100% 875M/877M [00:20<00:00, 69.1MB/s]\n",
            "100% 877M/877M [00:20<00:00, 44.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hcj6NTnyLPt",
        "outputId": "1838f986-3c8d-48fd-b414-fcf622034c96"
      },
      "source": [
        "\n",
        "!mv test.csv.zip data/test.csv.zip\n",
        "!mv train.csv.zip data/train.csv.zip\n",
        "!cd data; unzip train.csv.zip; unzip test.csv.zip\n",
        "!ls data"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'test.csv.zip': No such file or directory\n",
            "mv: cannot stat 'train.csv.zip': No such file or directory\n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n",
            "artifacts  data  models  sample_submission.csv.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSDvSZq3yXKy"
      },
      "source": [
        "df = pd.read_csv('data/train.csv')\n",
        "test_df = pd.read_csv('data/test.csv')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5X4VLR4zTA8"
      },
      "source": [
        "pd.set_option(\"display.max_rows\", 999)\n",
        "pd.set_option(\"display.max_columns\", 999)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm26mKhFzXxr"
      },
      "source": [
        "# Massaging Data\n",
        "\n",
        "These are taken from Kaggle notebooks (see commented code)\n",
        "\n",
        "\n",
        "1.   Memory optimization \n",
        "     * scans each column and based on the numeric range, sets the type to the one that requires the least memory\n",
        "     * improves performance because the datasets are very large\n",
        "2.   Imputation\n",
        "     * uses sklearn's iterative imputer which approximates the missing values based on \"nearby\" values.\n",
        "     * improves scores\n",
        "     * note that it takes a while, so for this notebook, the massaged data is being saved locally\n",
        "3.   additional columns are added to indicate the number of rows missing data and the missing feature columns\n",
        "4.  Another option seen in other competition notebooks: replace nulls with mean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dQrGpGF0cwL"
      },
      "source": [
        "RUN_MASSAGE = True"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYpd-_Ew0iIe"
      },
      "source": [
        "# https://www.kaggle.com/lucamassaron/autogluon-for-tabular-playground-sep-2021\n",
        "# Derived from the original script https://www.kaggle.com/gemartin/load-data-reduce-memory-usage \n",
        "# by Guillaume Martin\n",
        "\n",
        "# This checks the range of values in each column and resets the type \n",
        "\n",
        "def reduce_mem_usage(df, verbose=True):\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)    \n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "    return df"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aDXVq_I0mV4",
        "outputId": "92a47518-cd10-48b0-b630-5ac24c9f957e"
      },
      "source": [
        "df = reduce_mem_usage(df)\n",
        "test_df = reduce_mem_usage(test_df)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mem. usage decreased to 963.21 Mb (56.0% reduction)\n",
            "Mem. usage decreased to 481.13 Mb (55.9% reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKqJ2haF0-Xs"
      },
      "source": [
        "if RUN_MASSAGE:\n",
        "  X = df.drop(columns = ['id', 'target'])\n",
        "  test_X = test_df.drop(columns = ['id'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sduMJzZISad"
      },
      "source": [
        "### Iterative Imputation (requires high RAM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMwA9J_v0pue"
      },
      "source": [
        "#https://www.kaggle.com/lucamassaron/autogluon-for-tabular-playground-sep-2021\n",
        "# Reference: https://www.kaggle.com/hsuchialun/tps-lightgbm-kfold\n",
        "if RUN_MASSAGE:\n",
        "    feats = list(X.columns[:-1])\n",
        "\n",
        "    X['n_row_missing'] = X[feats].isna().sum(axis=1)\n",
        "    test_X['n_row_missing'] = test_X[feats].isna().sum(axis=1)\n",
        "\n",
        "    X['row_std'] = X[feats].std(axis=1)\n",
        "    test_X['row_std'] = test_X[feats].std(axis=1)\n",
        "\n",
        "    feats += ['n_row_missing', 'row_std']\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkVDNhI70vAP"
      },
      "source": [
        "# MULTIVARIATE ITERATIVE IMPUTATION\n",
        "\n",
        "if RUN_MASSAGE:\n",
        "    \n",
        "    imp = IterativeImputer(max_iter=10, random_state=0)\n",
        "    imp.fit(X[feats].sample(n=10_000))\n",
        "\n",
        "    X[feats] = imp.transform(X[feats])\n",
        "    test_X[feats] = imp.transform(test_X[feats])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEhGKakr2SLz"
      },
      "source": [
        "if RUN_MASSAGE:\n",
        "    pd.DataFrame(X).to_csv('./data/reduced_mem_imputed.csv', index=False)\n",
        "    pd.DataFrame(test_X).to_csv('./data/reduced_mem_imputed_test.csv', index=False)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7OBmr152bYO"
      },
      "source": [
        "X = pd.read_csv('./reduced_mem_imputed.csv')\n",
        "test_X = pd.read_csv('./reduced_mem_imputed_test.csv') # this is the Kaggle test dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rs7cK6Nv4n3J"
      },
      "source": [
        "# Alternative Imputing\n",
        "\n",
        "Below ONLY outlines what I saw in some other notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7Or70964yHq"
      },
      "source": [
        "# https://www.kaggle.com/hsuchialun/tps-lightgbm-kfold\n",
        "\n",
        "FEATURES = list(df.columns[:-1])\n",
        "TARGET = df.columns[-1]  # for this dataset, target is the last column\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DXZ4DEw_Vkh"
      },
      "source": [
        "df[FEATURES] = df[FEATURES].fillna(df[FEATURES].mean()) # have also seen mode\n",
        "test_df[FEATURES] = test_df[FEATURES].fillna(test_df[FEATURES].mean())\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxgthR-u_WoH"
      },
      "source": [
        "df.to_csv('mean_imputed_train.csv', index=False)\n",
        "test_df.to_csv('mean_imputed_test.csv', index=False)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5ltTQzlRwYu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}